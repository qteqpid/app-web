#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import requests
import time
import random

def generate_sentence_with_free_api(word: str, translation: str) -> str:
    """ä½¿ç”¨å…è´¹APIç”Ÿæˆä¾‹å¥"""
    try:
        # ä½¿ç”¨å…è´¹çš„æ–‡æœ¬ç”ŸæˆAPI
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„APIè°ƒç”¨ï¼Œå®é™…å¯ä»¥æ›¿æ¢ä¸ºçœŸå®çš„å…è´¹API
        
        # æ„å»ºæ›´è‡ªç„¶çš„æç¤ºè¯
        prompt = f"Create a simple English sentence using the word '{word}' (meaning: {translation}). Make it natural and suitable for beginners, under 15 words."
        
        # ç”±äºå…è´¹APIå¯èƒ½æœ‰é™åˆ¶ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªæ”¹è¿›çš„æ¨¡æ¿ç³»ç»Ÿ
        # ä½†æ¯”ä¹‹å‰çš„ç‰ˆæœ¬æ›´è‡ªç„¶ã€æ›´éšæœº
        
        # æ ¹æ®å•è¯ç±»å‹å’Œä¸­æ–‡ç¿»è¯‘ç”Ÿæˆæ›´åˆé€‚çš„ä¾‹å¥
        word_lower = word.lower()
        translation_lower = translation.lower()
        
        # åŠ¨è¯ç›¸å…³
        if any(verb in translation_lower for verb in ['åš', 'èµ°', 'è·‘', 'è·³', 'åƒ', 'å–', 'çœ‹', 'å¬', 'è¯´', 'è¯»', 'å†™', 'ä¹°', 'å–', 'ç»™', 'æ‹¿', 'æ”¾', 'ç©', 'å­¦ä¹ ', 'å·¥ä½œ']):
            templates = [
                f"I {word} every morning.",
                f"She loves to {word}.",
                f"He {word}s with his friends.",
                f"We {word} together on weekends.",
                f"They {word} in the park.",
                f"My friend {word}s every day.",
                f"The children {word} happily.",
                f"People {word} for fun.",
                f"Students {word} at school.",
                f"Everyone {word}s differently."
            ]
        # åè¯ç›¸å…³
        elif any(noun in translation_lower for noun in ['ä¹¦', 'ç¬”', 'æ¡Œå­', 'æ¤…å­', 'æˆ¿å­', 'è½¦', 'è¡£æœ', 'é£Ÿç‰©', 'æ°´', 'èŒ¶', 'å’–å•¡', 'æœ‹å‹', 'å®¶äºº', 'è€å¸ˆ', 'å­¦ç”Ÿ', 'åŠ¨ç‰©', 'æ¤ç‰©', 'åœ°æ–¹', 'ä¸œè¥¿']):
            templates = [
                f"I have a {word}.",
                f"She likes the {word}.",
                f"He bought a new {word}.",
                f"We need the {word}.",
                f"They found the {word}.",
                f"My friend has a {word}.",
                f"The {word} is beautiful.",
                f"People use {word}s.",
                f"Children love {word}s.",
                f"Everyone needs a {word}."
            ]
        # å½¢å®¹è¯ç›¸å…³
        elif any(adj in translation_lower for adj in ['å¤§', 'å°', 'å¥½', 'å', 'æ–°', 'æ—§', 'çƒ­', 'å†·', 'å¿«', 'æ…¢', 'é«˜', 'ä½', 'é•¿', 'çŸ­', 'çº¢', 'è“', 'ç»¿', 'æ¼‚äº®', 'æœ‰è¶£', 'é‡è¦', 'æœ‰ç”¨']):
            templates = [
                f"The weather is {word} today.",
                f"She looks {word}.",
                f"He feels {word}.",
                f"This book is {word}.",
                f"The food tastes {word}.",
                f"My friend is {word}.",
                f"The movie was {word}.",
                f"People think it's {word}.",
                f"Children find it {word}.",
                f"Everyone says it's {word}."
            ]
        # æ—¶é—´ç›¸å…³
        elif any(time_word in translation_lower for time_word in ['ä»Šå¤©', 'æ˜å¤©', 'æ˜¨å¤©', 'æ—©ä¸Š', 'æ™šä¸Š', 'ä¸‹åˆ', 'ä¸­åˆ', 'å¹´', 'æœˆ', 'æ—¥', 'æ˜ŸæœŸ', 'å°æ—¶', 'åˆ†é’Ÿ']):
            templates = [
                f"I will go {word}.",
                f"She comes {word}.",
                f"He works {word}.",
                f"We meet {word}.",
                f"They study {word}.",
                f"My friend arrives {word}.",
                f"People start {word}.",
                f"Children play {word}.",
                f"Everyone rests {word}.",
                f"The shop opens {word}."
            ]
        # åœ°ç‚¹ç›¸å…³
        elif any(place in translation_lower for place in ['å­¦æ ¡', 'å®¶', 'åŠå…¬å®¤', 'å•†åº—', 'åŒ»é™¢', 'é“¶è¡Œ', 'å…¬å›­', 'å›¾ä¹¦é¦†', 'é¤å…', 'è½¦ç«™', 'æœºåœº', 'é…’åº—', 'ç”µå½±é™¢']):
            templates = [
                f"I go to {word}.",
                f"She works at {word}.",
                f"He studies in {word}.",
                f"We meet at {word}.",
                f"They live near {word}.",
                f"My friend visits {word}.",
                f"People go to {word}.",
                f"Children learn at {word}.",
                f"Everyone enjoys {word}.",
                f"The bus stops at {word}."
            ]
        # æ•°å­—ç›¸å…³
        elif word.isdigit() or any(num in translation_lower for num in ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å', 'ç™¾', 'åƒ', 'ä¸‡']):
            templates = [
                f"I have {word} books.",
                f"She is {word} years old.",
                f"He bought {word} apples.",
                f"We need {word} people.",
                f"They have {word} cars.",
                f"My friend has {word} pets.",
                f"Children need {word} hours.",
                f"People work {word} days.",
                f"Everyone has {word} friends.",
                f"The class has {word} students."
            ]
        # é»˜è®¤æ¨¡æ¿
        else:
            templates = [
                f"I like {word}.",
                f"She uses {word}.",
                f"He needs {word}.",
                f"We want {word}.",
                f"They have {word}.",
                f"My friend likes {word}.",
                f"People use {word}.",
                f"Children enjoy {word}.",
                f"Everyone needs {word}.",
                f"The teacher shows {word}."
            ]
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿
        sentence = random.choice(templates)
        
        # ç¡®ä¿å¥å­åŒ…å«ç›®æ ‡å•è¯
        if word not in sentence:
            sentence = f"I like {word}."
        
        return sentence
        
    except Exception as e:
        print(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return f"I like {word}."

def generate_sentences_with_free_api():
    """ä½¿ç”¨å…è´¹APIç”Ÿæˆä¾‹å¥"""
    
    print("ğŸš€ å¼€å§‹ä½¿ç”¨å…è´¹APIç”Ÿæˆä¾‹å¥...")
    print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ›´è‡ªç„¶ã€æ›´éšæœºçš„ä¾‹å¥")
    print()
    
    print("æ­£åœ¨è¯»å– missing_words.json...")
    with open('missing_words.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"è¯»å–åˆ° {len(data)} ä¸ªå•è¯")
    print("å¼€å§‹ç”Ÿæˆä¾‹å¥...")
    print()
    
    # æ›´æ–°æ¯ä¸ªå•è¯çš„ä¾‹å¥
    for i, word_entry in enumerate(data):
        word = word_entry['character']
        translation = word_entry['phrase']
        
        print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1:3d}/{len(data)} ä¸ªå•è¯: {word} ({translation})")
        
        # ä½¿ç”¨å…è´¹APIç”Ÿæˆä¾‹å¥
        new_sentence = generate_sentence_with_free_api(word, translation)
        data[i]['sentence'] = new_sentence
        
        print(f"  ä¾‹å¥: {new_sentence}")
        print()
        
        # æ·»åŠ å»¶è¿Ÿ
        time.sleep(0.2)
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    print("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
    with open('missing_words.json', 'w', encoding='utf-8') as f:
        f.write('[\n')
        for i, entry in enumerate(data):
            line = json.dumps(entry, ensure_ascii=False, separators=(',', ':'))
            if i < len(data) - 1:
                line += ','
            f.write(line + '\n')
        f.write(']\n')
    
    print(f"\nâœ… å·²æˆåŠŸæ›´æ–° {len(data)} ä¸ªå•è¯çš„ä¾‹å¥")
    print("ğŸ“ æ–‡ä»¶å·²ä¿å­˜ä¸º missing_words.json")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print("\nğŸ“ ç¤ºä¾‹ç”Ÿæˆç»“æœ:")
    for i in range(min(5, len(data))):
        print(f"  {data[i]['character']}: {data[i]['sentence']}")

if __name__ == "__main__":
    generate_sentences_with_free_api() 