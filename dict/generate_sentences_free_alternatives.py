#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import requests
import time
import random
import urllib.parse

class FreeSentenceGenerator:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        })
    
    def generate_with_rapidapi(self, word: str, translation: str) -> str:
        """ä½¿ç”¨RapidAPIçš„å…è´¹æ–‡æœ¬ç”ŸæˆæœåŠ¡"""
        try:
            # ä½¿ç”¨RapidAPIä¸Šçš„å…è´¹æ–‡æœ¬ç”ŸæˆAPI
            url = "https://text-generator-api.p.rapidapi.com/generate"
            
            headers = {
                "X-RapidAPI-Key": "YOUR_RAPIDAPI_KEY",  # éœ€è¦æ³¨å†Œè·å–å…è´¹å¯†é’¥
                "X-RapidAPI-Host": "text-generator-api.p.rapidapi.com"
            }
            
            payload = {
                "prompt": f"Generate a simple English sentence using the word '{word}' (meaning: {translation}). Keep it under 15 words for beginners.",
                "max_tokens": 30
            }
            
            response = self.session.post(url, json=payload, headers=headers, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                sentence = result.get('generated_text', '').strip()
                if sentence and len(sentence) > 5:
                    return self.clean_sentence(sentence)
            
            return ""
            
        except Exception as e:
            print(f"RapidAPIè°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def generate_with_huggingface_free(self, word: str, translation: str) -> str:
        """ä½¿ç”¨Hugging Faceçš„å…è´¹æ¨ç†API"""
        try:
            # ä½¿ç”¨Hugging Faceçš„å…è´¹æ¨ç†ç«¯ç‚¹
            url = "https://api-inference.huggingface.co/models/gpt2"
            
            headers = {
                "Authorization": "Bearer hf_xxx"  # éœ€è¦æ³¨å†Œè·å–å…è´¹token
            }
            
            payload = {
                "inputs": f"Generate a simple English sentence using '{word}' (meaning: {translation}):",
                "parameters": {
                    "max_new_tokens": 25,
                    "temperature": 0.7,
                    "do_sample": True
                }
            }
            
            response = self.session.post(url, json=payload, headers=headers, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    generated_text = result[0].get('generated_text', '')
                    sentence = generated_text.split(':', 1)[-1].strip()
                    return self.clean_sentence(sentence)
            
            return ""
            
        except Exception as e:
            print(f"Hugging Faceå…è´¹APIè°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def generate_with_ai21_free(self, word: str, translation: str) -> str:
        """ä½¿ç”¨AI21çš„å…è´¹API"""
        try:
            url = "https://api.ai21.com/studio/v1/j1-jumbo/complete"
            
            headers = {
                "Authorization": "Bearer YOUR_AI21_KEY",  # éœ€è¦æ³¨å†Œè·å–å…è´¹å¯†é’¥
                "Content-Type": "application/json"
            }
            
            payload = {
                "prompt": f"Generate a simple English sentence using the word '{word}' (meaning: {translation}). Keep it under 15 words for beginners:",
                "numResults": 1,
                "maxTokens": 25,
                "temperature": 0.7
            }
            
            response = self.session.post(url, json=payload, headers=headers, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                completions = result.get('completions', [])
                if completions:
                    sentence = completions[0].get('data', {}).get('text', '').strip()
                    return self.clean_sentence(sentence)
            
            return ""
            
        except Exception as e:
            print(f"AI21 APIè°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def generate_with_web_scraping(self, word: str, translation: str) -> str:
        """é€šè¿‡ç½‘é¡µæŠ“å–è·å–ä¾‹å¥"""
        try:
            # å°è¯•ä»åœ¨çº¿è¯å…¸ç½‘ç«™è·å–ä¾‹å¥
            search_urls = [
                f"https://dictionary.cambridge.org/dictionary/english/{word}",
                f"https://www.merriam-webster.com/dictionary/{word}",
                f"https://www.collinsdictionary.com/dictionary/english/{word}"
            ]
            
            for url in search_urls:
                try:
                    response = self.session.get(url, timeout=10)
                    if response.status_code == 200:
                        # è¿™é‡Œéœ€è¦è§£æHTMLæ¥æå–ä¾‹å¥
                        # ç®€åŒ–ç‰ˆæœ¬ï¼šè¿”å›åŸºäºæ¨¡æ¿çš„ä¾‹å¥
                        return self.generate_template_sentence(word, translation)
                except:
                    continue
            
            return ""
            
        except Exception as e:
            print(f"ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
            return ""
    
    def generate_with_community_api(self, word: str, translation: str) -> str:
        """ä½¿ç”¨ç¤¾åŒºç»´æŠ¤çš„å…è´¹API"""
        try:
            # ä½¿ç”¨ä¸€äº›ç¤¾åŒºç»´æŠ¤çš„å…è´¹æ–‡æœ¬ç”ŸæˆAPI
            apis = [
                {
                    "url": "https://api.text-generator.com/generate",
                    "method": "POST",
                    "headers": {"Content-Type": "application/json"},
                    "data": {
                        "prompt": f"Simple English sentence with '{word}':",
                        "max_length": 50
                    }
                }
            ]
            
            for api in apis:
                try:
                    response = self.session.request(
                        api["method"], 
                        api["url"], 
                        json=api["data"], 
                        headers=api["headers"], 
                        timeout=10
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        sentence = result.get('text', '').strip()
                        if sentence:
                            return self.clean_sentence(sentence)
                            
                except Exception as e:
                    print(f"ç¤¾åŒºAPIè°ƒç”¨å¤±è´¥: {e}")
                    continue
            
            return ""
            
        except Exception as e:
            print(f"ç¤¾åŒºAPIè°ƒç”¨å¤±è´¥: {e}")
            return ""
    
    def generate_template_sentence(self, word: str, translation: str) -> str:
        """ä½¿ç”¨æ”¹è¿›çš„æ¨¡æ¿ç”Ÿæˆä¾‹å¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # æ›´ä¸°å¯Œçš„æ¨¡æ¿åº“
        templates = [
            # åŸºç¡€å¥å‹
            f"I like {word}.",
            f"She uses {word}.",
            f"He needs {word}.",
            f"We want {word}.",
            f"They have {word}.",
            
            # å¸¦ä¿®é¥°è¯­çš„å¥å‹
            f"I really like {word}.",
            f"She often uses {word}.",
            f"He always needs {word}.",
            f"We sometimes want {word}.",
            f"They usually have {word}.",
            
            # å¸¦æ—¶é—´åœ°ç‚¹çš„å¥å‹
            f"I like {word} every day.",
            f"She uses {word} at home.",
            f"He needs {word} at school.",
            f"We want {word} on weekends.",
            f"They have {word} in the morning.",
            
            # å¸¦å½¢å®¹è¯çš„å¥å‹
            f"I like the {word}.",
            f"She uses a {word}.",
            f"He needs the {word}.",
            f"We want a {word}.",
            f"They have the {word}.",
            
            # æ›´å¤æ‚çš„å¥å‹
            f"My friend likes {word}.",
            f"The teacher shows {word}.",
            f"Children enjoy {word}.",
            f"People use {word}.",
            f"Everyone needs {word}.",
            
            # åŠ¨è¯å˜åŒ–
            f"I am using {word}.",
            f"She is looking at {word}.",
            f"He is working with {word}.",
            f"We are studying {word}.",
            f"They are playing with {word}.",
            
            # è¿‡å»æ—¶
            f"I used {word} yesterday.",
            f"She bought {word} last week.",
            f"He found {word}.",
            f"We saw {word}.",
            f"They made {word}.",
            
            # å°†æ¥æ—¶
            f"I will use {word}.",
            f"She will buy {word}.",
            f"He will need {word}.",
            f"We will want {word}.",
            f"They will have {word}."
        ]
        
        # æ ¹æ®å•è¯ç±»å‹é€‰æ‹©æ›´åˆé€‚çš„æ¨¡æ¿
        word_lower = word.lower()
        translation_lower = translation.lower()
        
        # åŠ¨è¯ç›¸å…³
        if any(verb in translation_lower for verb in ['åš', 'èµ°', 'è·‘', 'è·³', 'åƒ', 'å–', 'çœ‹', 'å¬', 'è¯´', 'è¯»', 'å†™', 'ä¹°', 'å–', 'ç»™', 'æ‹¿', 'æ”¾', 'ç©', 'å­¦ä¹ ', 'å·¥ä½œ']):
            verb_templates = [
                f"I {word} every morning.",
                f"She loves to {word}.",
                f"He {word}s with his friends.",
                f"We {word} together.",
                f"They {word} in the park.",
                f"My friend {word}s every day.",
                f"The children {word} happily.",
                f"People {word} for fun.",
                f"Students {word} at school.",
                f"Everyone {word}s differently."
            ]
            templates.extend(verb_templates)
        
        # å½¢å®¹è¯ç›¸å…³
        elif any(adj in translation_lower for adj in ['å¤§', 'å°', 'å¥½', 'å', 'æ–°', 'æ—§', 'çƒ­', 'å†·', 'å¿«', 'æ…¢', 'é«˜', 'ä½', 'é•¿', 'çŸ­', 'çº¢', 'è“', 'ç»¿', 'æ¼‚äº®', 'æœ‰è¶£', 'é‡è¦', 'æœ‰ç”¨']):
            adj_templates = [
                f"The weather is {word} today.",
                f"She looks {word}.",
                f"He feels {word}.",
                f"This book is {word}.",
                f"The food tastes {word}.",
                f"My friend is {word}.",
                f"The movie was {word}.",
                f"People think it's {word}.",
                f"Children find it {word}.",
                f"Everyone says it's {word}."
            ]
            templates.extend(adj_templates)
        
        # åè¯ç›¸å…³
        elif any(noun in translation_lower for noun in ['ä¹¦', 'ç¬”', 'æ¡Œå­', 'æ¤…å­', 'æˆ¿å­', 'è½¦', 'è¡£æœ', 'é£Ÿç‰©', 'æ°´', 'èŒ¶', 'å’–å•¡', 'æœ‹å‹', 'å®¶äºº', 'è€å¸ˆ', 'å­¦ç”Ÿ', 'åŠ¨ç‰©', 'æ¤ç‰©', 'åœ°æ–¹', 'ä¸œè¥¿']):
            noun_templates = [
                f"I have a {word}.",
                f"She likes the {word}.",
                f"He bought a new {word}.",
                f"We need the {word}.",
                f"They found the {word}.",
                f"My friend has a {word}.",
                f"The {word} is beautiful.",
                f"People use {word}s.",
                f"Children love {word}s.",
                f"Everyone needs a {word}."
            ]
            templates.extend(noun_templates)
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿
        sentence = random.choice(templates)
        
        # ç¡®ä¿å¥å­åŒ…å«ç›®æ ‡å•è¯
        if word not in sentence:
            sentence = f"I like {word}."
        
        return sentence
    
    def clean_sentence(self, sentence: str) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–å¥å­"""
        # ç§»é™¤å¤šä½™çš„å¼•å·å’Œæ ‡ç‚¹
        sentence = sentence.strip('"').strip("'").strip()
        
        # ç¡®ä¿å¥å­ä»¥å¥å·ç»“å°¾
        if not sentence.endswith('.'):
            sentence += '.'
        
        # ç¡®ä¿é¦–å­—æ¯å¤§å†™
        if sentence and sentence[0].islower():
            sentence = sentence[0].upper() + sentence[1:]
        
        return sentence
    
    def generate_sentence(self, word: str, translation: str) -> str:
        """å°è¯•å¤šç§å…è´¹æ–¹æ³•ç”Ÿæˆä¾‹å¥"""
        methods = [
            ('RapidAPI', lambda: self.generate_with_rapidapi(word, translation)),
            ('Hugging Face Free', lambda: self.generate_with_huggingface_free(word, translation)),
            ('AI21 Free', lambda: self.generate_with_ai21_free(word, translation)),
            ('Web Scraping', lambda: self.generate_with_web_scraping(word, translation)),
            ('Community API', lambda: self.generate_with_community_api(word, translation))
        ]
        
        for method_name, method_func in methods:
            print(f"  å°è¯•ä½¿ç”¨ {method_name}...")
            result = method_func()
            if result:
                print(f"  âœ… {method_name} ç”ŸæˆæˆåŠŸ")
                return result
            else:
                print(f"  âŒ {method_name} ç”Ÿæˆå¤±è´¥")
        
        # å¦‚æœæ‰€æœ‰å…è´¹æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›çš„æ¨¡æ¿
        print("  ğŸ”„ ä½¿ç”¨æ”¹è¿›æ¨¡æ¿ç”Ÿæˆ")
        return self.generate_template_sentence(word, translation)

def generate_sentences_with_free_alternatives():
    """ä½¿ç”¨å…è´¹æ›¿ä»£æ–¹æ¡ˆç”Ÿæˆä¾‹å¥"""
    
    print("ğŸš€ å¼€å§‹ä½¿ç”¨å…è´¹æ›¿ä»£æ–¹æ¡ˆç”Ÿæˆä¾‹å¥...")
    print("ğŸ“ å°è¯•å¤šç§å…è´¹APIå’ŒæœåŠ¡")
    print("ğŸ’¡ æç¤º: æŸäº›APIå¯èƒ½éœ€è¦æ³¨å†Œè·å–å…è´¹å¯†é’¥")
    print()
    
    generator = FreeSentenceGenerator()
    
    print("æ­£åœ¨è¯»å– missing_words.json...")
    with open('missing_words.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"è¯»å–åˆ° {len(data)} ä¸ªå•è¯")
    print("å¼€å§‹ç”Ÿæˆä¾‹å¥...")
    print()
    
    # æ›´æ–°æ¯ä¸ªå•è¯çš„ä¾‹å¥
    for i, word_entry in enumerate(data):
        word = word_entry['character']
        translation = word_entry['phrase']
        
        print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1:3d}/{len(data)} ä¸ªå•è¯: {word} ({translation})")
        
        # ä½¿ç”¨å…è´¹æ›¿ä»£æ–¹æ¡ˆç”Ÿæˆä¾‹å¥
        new_sentence = generator.generate_sentence(word, translation)
        data[i]['sentence'] = new_sentence
        
        print(f"  ä¾‹å¥: {new_sentence}")
        print()
        
        # æ·»åŠ å»¶è¿Ÿ
        time.sleep(0.5)
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    print("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
    with open('missing_words.json', 'w', encoding='utf-8') as f:
        f.write('[\n')
        for i, entry in enumerate(data):
            line = json.dumps(entry, ensure_ascii=False, separators=(',', ':'))
            if i < len(data) - 1:
                line += ','
            f.write(line + '\n')
        f.write(']\n')
    
    print(f"\nâœ… å·²æˆåŠŸæ›´æ–° {len(data)} ä¸ªå•è¯çš„ä¾‹å¥")
    print("ğŸ“ æ–‡ä»¶å·²ä¿å­˜ä¸º missing_words.json")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print("\nğŸ“ ç¤ºä¾‹ç”Ÿæˆç»“æœ:")
    for i in range(min(5, len(data))):
        print(f"  {data[i]['character']}: {data[i]['sentence']}")

if __name__ == "__main__":
    generate_sentences_with_free_alternatives() 