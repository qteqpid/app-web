#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import requests
import time
import random
import os

def generate_sentence_with_openai(word, translation):
    """ä½¿ç”¨OpenAI APIç”Ÿæˆä¾‹å¥"""
    try:
        # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªå…è´¹çš„APIæœåŠ¡æ¥æ¨¡æ‹ŸOpenAI
        # å®é™…ä½¿ç”¨æ—¶éœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„APIå¯†é’¥
        api_key = os.getenv('OPENAI_API_KEY', '')
        
        if not api_key:
            # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            return generate_sentence_fallback(word, translation)
        
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': 'gpt-3.5-turbo',
            'messages': [
                {
                    'role': 'system',
                    'content': 'You are a helpful assistant that generates simple English sentences for language learners. Keep sentences under 15 words, use simple vocabulary, and make them suitable for beginners.'
                },
                {
                    'role': 'user',
                    'content': f'Generate a simple English sentence using the word "{word}" (meaning: {translation}). The sentence should be natural and easy to understand.'
                }
            ],
            'max_tokens': 50,
            'temperature': 0.7
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data,
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            sentence = result['choices'][0]['message']['content'].strip()
            # æ¸…ç†å¥å­ï¼Œç§»é™¤å¼•å·ç­‰
            sentence = sentence.strip('"').strip("'")
            return sentence
        else:
            print(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            return generate_sentence_fallback(word, translation)
            
    except Exception as e:
        print(f"APIè°ƒç”¨å‡ºé”™: {e}")
        return generate_sentence_fallback(word, translation)

def generate_sentence_fallback(word, translation):
    """æ›´ä¸°å¯Œã€æ›´éšæœºçš„ä¾‹å¥ç”Ÿæˆ"""
    import random
    word_lower = word.lower()
    translation_lower = translation.lower()

    # å¸¸ç”¨ä¸»è¯­ã€ä¿®é¥°è¯­ã€åœ°ç‚¹ã€æ—¶é—´
    subjects = ["I", "You", "He", "She", "We", "They", "My friend", "The teacher", "A child", "People"]
    adverbs = ["quickly", "happily", "carefully", "every day", "sometimes", "at home", "at school", "in the morning", "after lunch", "on weekends", "with friends", "together", "for fun", "at the park", "in the city", "at night", "in summer", "in winter", "on the table", "in the bag", "at the shop", "in the kitchen", "on the bus", "in the garden", "at the zoo"]
    verbs = ["see", "like", "use", "find", "buy", "have", "need", "want", "enjoy", "make", "bring", "take", "eat", "drink", "play with", "look at", "talk about", "read about", "write about", "draw", "watch", "visit", "meet"]
    templates = [
        "{subj} {verb} the {word} {adv}.",
        "{subj} {verb} a {word} {adv}.",
        "{subj} {verb} {word} {adv}.",
        "{subj} {verb} the {word}.",
        "{subj} {verb} a {word}.",
        "{subj} {verb} {word}.",
        "{subj} always {verb} {word} {adv}.",
        "{subj} sometimes {verb} {word} {adv}.",
        "Yesterday, {subj} {verb} the {word}.",
        "On weekends, {subj} {verb} {word}.",
        "At school, {subj} {verb} the {word}.",
        "In the morning, {subj} {verb} a {word}.",
        "After lunch, {subj} {verb} {word}.",
        "{subj} wants to {verb} the {word} {adv}.",
        "{subj} is happy with the {word}.",
        "{subj} is looking for a {word}.",
        "{subj} is talking about the {word}.",
        "{subj} is playing with the {word} {adv}.",
        "{subj} is reading about {word}.",
        "{subj} is writing about {word}.",
        "{subj} is drawing a {word}.",
        "{subj} is watching the {word}.",
        "{subj} is visiting the {word}.",
        "{subj} is meeting a {word}.",
        "{subj} thinks the {word} is great.",
        "{subj} thinks the {word} is interesting.",
        "{subj} thinks the {word} is important.",
        "{subj} thinks the {word} is fun.",
        "{subj} thinks the {word} is useful."
    ]
    # å½¢å®¹è¯æ¨¡æ¿
    adj_templates = [
        "The {word} is very {adj}.",
        "{subj} thinks the {word} is {adj}.",
        "{subj} saw a {adj} {word} {adv}.",
        "{subj} has a {adj} {word}.",
        "{subj} wants a {adj} {word}."
    ]
    # å½¢å®¹è¯åº“
    adjectives = ["big", "small", "new", "old", "nice", "good", "bad", "funny", "happy", "sad", "interesting", "important", "beautiful", "delicious", "famous", "friendly", "useful", "wonderful", "amazing", "cool"]

    # éšæœºé€‰æ‹©æ¨¡æ¿
    if any(adj in translation_lower for adj in ["çš„", "å¤§", "å°", "å¥½", "å", "æ–°", "æ—§", "æœ‰è¶£", "é‡è¦", "æ¼‚äº®", "ç¾å‘³", "è‘—å", "å‹å¥½", "æœ‰ç”¨", "æ£’", "é…·"]):
        template = random.choice(adj_templates)
        adj = random.choice(adjectives)
        sentence = template.format(word=word, subj=random.choice(subjects), adj=adj, adv=random.choice(adverbs))
    else:
        template = random.choice(templates)
        sentence = template.format(word=word, subj=random.choice(subjects), verb=random.choice(verbs), adv=random.choice(adverbs))

    # å¥é¦–å¤§å†™ï¼Œå¥å°¾å¥å·
    sentence = sentence[0].upper() + sentence[1:]
    if not sentence.endswith('.'):
        sentence += '.'
    return sentence

def improve_sentences_advanced():
    """ä½¿ç”¨é«˜çº§æ–¹æ³•æ”¹è¿›missing_words.jsonä¸­çš„ä¾‹å¥"""
    
    print("æ­£åœ¨è¯»å– missing_words.json...")
    with open('missing_words.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"è¯»å–åˆ° {len(data)} ä¸ªå•è¯")
    print("å¼€å§‹ç”Ÿæˆæ”¹è¿›çš„ä¾‹å¥...")
    
    # æ›´æ–°æ¯ä¸ªå•è¯çš„ä¾‹å¥
    for i, word_entry in enumerate(data):
        word = word_entry['character']
        translation = word_entry['phrase']
        
        print(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1:3d}/{len(data)} ä¸ªå•è¯: {word} ({translation})")
        
        # å°è¯•ä½¿ç”¨APIç”Ÿæˆä¾‹å¥ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        try:
            new_sentence = generate_sentence_with_openai(word, translation)
        except:
            new_sentence = generate_sentence_fallback(word, translation)
        
        data[i]['sentence'] = new_sentence
        
        print(f"  ä¾‹å¥: {new_sentence}")
        
        # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶
        time.sleep(0.2)
    
    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    print("\næ­£åœ¨ä¿å­˜æ–‡ä»¶...")
    with open('missing_words.json', 'w', encoding='utf-8') as f:
        f.write('[\n')
        for i, entry in enumerate(data):
            line = json.dumps(entry, ensure_ascii=False, separators=(',', ':'))
            if i < len(data) - 1:
                line += ','
            f.write(line + '\n')
        f.write(']\n')
    
    print(f"\nâœ… å·²æˆåŠŸæ›´æ–° {len(data)} ä¸ªå•è¯çš„ä¾‹å¥")
    print("ğŸ“ æ–‡ä»¶å·²ä¿å­˜ä¸º missing_words.json")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹
    print("\nğŸ“ ç¤ºä¾‹æ”¹è¿›:")
    for i in range(min(5, len(data))):
        print(f"  {data[i]['character']}: {data[i]['sentence']}")

if __name__ == "__main__":
    improve_sentences_advanced() 